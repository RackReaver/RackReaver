<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on RackReaver</title>
        <link>/posts/</link>
        <description>Recent content in Posts on RackReaver</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Tue, 25 Jan 2022 12:41:42 -0500</lastBuildDate>
        <atom:link href="/posts/index.xml" rel="self" type="application/rss+xml" />
        
        <item>
            <title>Git for Document Management</title>
            <link>/posts/git-for-document-management/</link>
            <pubDate>Tue, 25 Jan 2022 12:41:42 -0500</pubDate>
            
            <guid>/posts/git-for-document-management/</guid>
            <description>The idea for this came to me while exploring and contributing to open source communities. It was (and still is) quite impressive how well these communities self govern using the Git version control system. Developers use the Git system to maintain a record of any changes to programming files and to me I couldn&amp;rsquo;t see why we couldn&amp;rsquo;t use the same system for documents.
The Markdown language One downside to using Git for document management is the need to use plain text files and the Markdown language.</description>
            <content type="html"><![CDATA[
    <img src="/images/posts/git-for-document-management.png"  alt="graphic-of-person-on-computer"  class="center"  style="border-radius: 8px;"  />


<p>The idea for this came to me while exploring and contributing to open source communities. It was (and still is) quite impressive how well these communities self govern using the Git version control system. Developers use the Git system to maintain a record of any changes to programming files and to me I couldn&rsquo;t see why we couldn&rsquo;t use the same system for documents.</p>
<h2 id="the-markdown-language">The Markdown language</h2>
<p>One downside to using Git for document management is the need to use plain text files and the Markdown language. Using software like Microsoft Office Suite or anything similar is not really possible due to the way Git tracks changes. Markdown is a very simplistic language and only provides basic support for formatting the document. To me this is actually quite powerful when it comes to document management because it requires an individual to simplify the document in a way that works with Markdown. Personally I am not a fan of long text heavy documents, no one reads them if they are long so why have them (exception being legal documents)?</p>
<h2 id="creating-commits">Creating commits</h2>
<p>This is actually difficult because all of the standards (i.e. conventional commits) revolves around software development and not document management. Because of this I decided to create my own that track important changes for document management and are as follows:</p>
<table>
<thead>
<tr>
<th>type</th>
<th>description</th>
</tr>
</thead>
<tbody>
<tr>
<td>new</td>
<td>When a document is being added to the repo for tracking</td>
</tr>
<tr>
<td>add</td>
<td>When new text is added to an existing document</td>
</tr>
<tr>
<td>update</td>
<td>When text is changed in an existing document</td>
</tr>
<tr>
<td>style</td>
<td>No text is changed only formatting</td>
</tr>
<tr>
<td>chore</td>
<td>Changes not affecting documents</td>
</tr>
</tbody>
</table>
<h3 id="example-commits">Example commits</h3>
<ul>
<li>new: Create incident response process document</li>
<li>add: Add point of contact table to incident response process</li>
<li>update: Change document owner to john doe</li>
<li>style: Change location of table of contents</li>
<li>chore: Move incident response plan to incident response folder</li>
</ul>
<h2 id="creating-and-managing-branches">Creating and managing branches</h2>
<p>Branches follow the same methodology that is used in software development. If a document needs to be added or altered a branch is created and all changes are made before making a pull request to update the main production documents. Anything living on the main or master branch are considered published documents and any other branches are considered pending changes.</p>
<h3 id="example-branches">Example branches</h3>
<ul>
<li>new/incident-response-process</li>
<li>add/add-point-of-contacts-to-incident-response-process</li>
<li>update/change-incident-response-process-document-owner</li>
<li>style/change-incident-response-process-table-of-contents-location</li>
<li>chore/move-incident-response-plan-to-incident-response-folder</li>
</ul>
]]></content>
        </item>
        
        <item>
            <title>How to Build a Simple Threat and Vulnerability Management Program</title>
            <link>/posts/how-to-build-a-simple-threat-and-vulnerability-management-program/</link>
            <pubDate>Mon, 05 Apr 2021 10:19:35 -0500</pubDate>
            
            <guid>/posts/how-to-build-a-simple-threat-and-vulnerability-management-program/</guid>
            <description>Vulnerability management has been a key part of my career in information security. I have built two full programs at this point, one at a fortune 200 company and another at sub one thousand employee company. From the perspective of information security the process and program were nearly identical in how they were built, the differences only show in the remediation process.
Choosing a Vulnerability Management Platform This is an important (if not the most important) part of a security organizations toolbox.</description>
            <content type="html"><![CDATA[
    <img src="/images/posts/how-to-build-a-simple-threat-and-vulnerability-management-program.jpeg"  alt="Hello Friend"  class="center"  style="border-radius: 8px;"  />


<p>Vulnerability management has been a key part of my career in information security. I have built two full programs at this point, one at a fortune 200 company and another at sub one thousand employee company. From the perspective of information security the process and program were nearly identical in how they were built, the differences only show in the remediation process.</p>
<h2 id="choosing-a-vulnerability-management-platform">Choosing a Vulnerability Management Platform</h2>
<p>This is an important (if not the most important) part of a security organizations toolbox. With the device count growing and the move to a remote workforce it is becoming increasingly important to implement a solution for monitoring individual assets. Work from home has created a big problem for infosec teams due to the vast number of unknown variables; is the home router up-to-date, are ports open on the firewall, what other devices sit on the home network, are the other devices up-to-date. This is where a good vulnerability platform comes in, my top three all have the ability to install agents on individual machines that can be scanned over the internet.</p>
<ol>
<li><a href="https://www.tenable.com/products/tenable-io">Tenable.io</a></li>
</ol>
<p>I am a Tenable guy, I consider it the industry standard in simplicity and effectiveness. They have recently been switching to a new interface which I am not a fan of but even with its shortcomings no other tool comes close to its performance.</p>
<ol start="2">
<li><a href="https://www.qualys.com/cloud-platform/">Qualys</a></li>
</ol>
<p>I personally don’t like Qualys, in my opinion it&rsquo;s a bit inefficient. It does the job and I can work with it, I would just be far more efficient and effective as a technical resource with Tenable. If you already have Qualys or have engineers familiar with the tool it will accomplish the task of scanning but not at the level of superior efficiency which is what I strive for.</p>
<ol start="3">
<li><a href="https://www.rapid7.com/products/nexpose/">Nexpose</a></li>
</ol>
<p>I have the least experience with this tool and could be a reason for it coming in third, however this doesn’t excuse it from being a bit clunky. I haven’t used it in over two years so I am hoping it&rsquo;s been refreshed to create a more efficient environment for program management.</p>
<h2 id="define-the-remediation-patching-timeline">Define the Remediation Patching Timeline</h2>
<p>Depending on the side of your operations team and compliance requirements this can differ. There really is no one size fits all way to define this, understand that the goal is to keep the timeline as close to immediate as reasonably possible. If you have any compliance requirements do yourself a favor and set it to the max allowed, it’s a pain trying to explain yourself out of not hitting the defined patching schedule to an auditor; you and your operations team can thank me later. Here is an example patching schedule:</p>
<table>
<thead>
<tr>
<th>Severity</th>
<th>CVSS</th>
<th>Patching Timeline</th>
</tr>
</thead>
<tbody>
<tr>
<td>Critical</td>
<td>9.0 - 10.0</td>
<td>5 Business Days</td>
</tr>
<tr>
<td>High</td>
<td>7.0 - 8.9</td>
<td>10 Business Days</td>
</tr>
<tr>
<td>Medium</td>
<td>4.0 - 6.9</td>
<td>15 Business Days</td>
</tr>
<tr>
<td>Low</td>
<td>0.1 - 3.9</td>
<td>30 Business Days</td>
</tr>
</tbody>
</table>
<p>If you are running a mature security program you can base the patching timeline off an internally defined metric that aligns with a risk registry. This allows you to redefine the patching timelines based on a business risk model instead of clear cut CVSS scores (check your compliance requirements though as this may not be an option). I have always found it labor intensive to manage and set up a risk registry, I only recommend it if you have the man hours to spare.</p>
<h2 id="define-the-scanning-schedule">Define the Scanning Schedule</h2>
<p>This always seems to be the defining moment for a vulnerability management program; getting the operations team onboard. This is especially difficult if there has never been scanning activity before. Vulnerability scans are notorious for accidentally finding configuration issues and errors throughout the infrastructure; this could easily cause outages on a semi-regular basis until the network is brought up to a secure baseline. I consider these configuration issues to be major vulnerabilities however they will likely not show on the scan but instead just break things throughout the network. Just be cautious when running scans on new networks in the organization and be sure to over communicate with the operations team.</p>
<p>An important thing to note about scanning is how to break down the networks. The goal should be to group them in a logical manner that suits the business, therefore use the following outline as a guideline for how to create scanning schedules in your organization.</p>
<h3 id="network-breakdown-options">Network Breakdown Options</h3>
<ol>
<li>
<p>Based on Region</p>
</li>
<li>
<p>Based on Responsible Team</p>
</li>
<li>
<p>Based on Office/Datacenter</p>
</li>
</ol>
<p>These three network breakdown options are what I have found to be most effective. I almost always break datacenters into individual scans first unless PCI is involved. I always separate scans for PCI to ensure the scope is limited to only what is needed for the certified scan.</p>
<h2 id="suggested-scan-types">Suggested Scan Types</h2>
<p><strong>Host Discovery Scans</strong></p>
<p>I mirror my host discovery scans to the vulnerability scans. I only use host scans on the monthly/quarterly scans to keep the IP list up-to-date. I usually want datacenter host scans happening on a weekly basis, they are low risk and give a clear picture of the asset count.</p>
<p><strong>Daily External Scans</strong></p>
<p>I do not believe permission or notice should be given to anyone when performing external scans, malicious threat actors don’t require approval to scan external facing devices and neither should the information security team.</p>
<p><strong>Corporate Office Scans</strong></p>
<p>I split office scans into one per office when possible, with larger organizations however I would go by region to reduce the number of scans that must be reviewed. Splitting the scans up allows you to compare them and create a risk rating by location. Tools like Tenable do have the ability to comb through all the scan results on one dashboard and filters are available but I find it more efficient to just build python scripts to review and manage individual scans.</p>
<p><strong>Production &amp; UAT/Dev Scans</strong></p>
<p>This is obviously dependent on if you have these environments, I would break them down based on region or datacenter. Both are viable options, I would make a decision based on the amount of assets; the goal should be a 2-3 hour scan.</p>
<p><strong>Compliance Scans</strong></p>
<p>I like all compliance related scans separate especially the ones for PCI. It is far easier to keep a tight scope for regulated networks [i.e. cardholder data environment] then trying to explain why some assets are out of scope to an auditor.</p>
<h2 id="meetings">Meetings</h2>
<p><strong>Monthly Status Meeting</strong></p>
<p>I set up a monthly meeting with the leads on the operations team to provide program updates and any process changes that might be required.</p>
<p><strong>Weekly Support Meeting</strong></p>
<p>I personally don’t do this anymore but am mentioning it for the inexperienced in vulnerability management. This is a great way to show your support to the operations team and allows for a scheduled troubleshooting; it is really unnecessary though, if you communicate well and are willing/able to answer questions on the fly I would just have them reach out when they have questions.</p>
<h2 id="program-maturity">Program Maturity</h2>
<p>To me this is simple, if it can be automated it should be. My career objective revolves around automation and yours should too. Scripting (specifically in Python 3.x) is not difficult to learn and will really enhance your engineering abilities, if this doesn’t interest you take a look at a tool I have working on <a href="https://github.com/RackReaver/AVMP">AVMP (Automated Vulnerability Management Program)</a> which is being built to automate the life cycle of vulnerability management. If setting up the tool is still too much for you feel free to reach out. I can help with basic troubleshooting and if hands on is required I can offer consulting.</p>
<h2 id="conclusion">Conclusion</h2>
<p>This is the basics to a vulnerability management program, in trying to avoid the fluff I am assuming questions will arise, feel free to comment or message me and I will update the FAQ at the bottom of the page with my responses.</p>
<h2 id="faq">FAQ</h2>
<p><strong>Why not do one big scan to cover all networks?</strong></p>
<p>The bigger the scan the longer it takes, I always want someone available on the information security team during scanning windows in case something goes wrong, we want to turn scans off if issues arise. It also allows for easier reporting and notification to the appropriate teams. I like scans to take no longer then about 2-3 hours unless the scans are compliance related as those are out of our control.</p>
<p><strong>Management is not onboard with the potential downtime on production?</strong></p>
<p>This is going to require some risk analysis which is not easy, estimating losses due to cyber attacks or breaches is no simple task, hopefully your team has a proficient CISO that is able to communicate this risk in terms of dollars, that always gets the CFO onboard.</p>
]]></content>
        </item>
        
    </channel>
</rss>
